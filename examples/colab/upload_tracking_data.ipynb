{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build Personalized AI HR models",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZdfdAQSt7hZ"
      },
      "source": [
        "##### Copyright 2020 HrFlow's AI Research Department\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNgz5iA-uD4E"
      },
      "source": [
        "# Copyright 2020 HrFlow's AI Research Department. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijYNoliXuIKP"
      },
      "source": [
        "<p>\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/Riminder/python-hrflow-api/blob/master/examples/colab/build_personalized_ai_hr_models.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/Riminder/python-hrflow-api/blob/master/examples/colab/build_personalized_ai_hr_models.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://www.hrflow.ai/book-us\">\n",
        "    <img width=32px src=\"https://gblobscdn.gitbook.com/spaces%2F-M1L6Hspq8r9LXd5_gIC%2Favatar-1586188377926.png?generation=1586188378327930&alt=media\" />Get an account</a>\n",
        "</td></table>\n",
        "<br>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtpcP2wIAu_K"
      },
      "source": [
        "<p>\n",
        "<table align=\"center\">\n",
        "<td>\n",
        "  <a target=\"_blank\"  href=\"https://developers.hrflow.ai/ai-layers/embedding\">\n",
        "    <img width=800px img src=\"https://lh3.googleusercontent.com/JXagdsThZxaEKwjE83-QrJXjB1r1tk2-KmdBzb94X_a238-5bNtwHuDi-PUA4_cVBkpaCie1uil6lPDNhdggpZhkgiZBYQGe4iKRRGo13XvyYgzuG9Vw_fv72LiYrg2am9MIrPnkwlQ\"/>\n",
        "  </a>\n",
        "</td>\n",
        "</table>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfFOG5klschh"
      },
      "source": [
        "Advantages of HrFlow.ai Embedding API:\n",
        "\n",
        "-  **Save 90% of R&D time** spent on features engineering \n",
        "\n",
        "- Train with **limited amount of labels**\n",
        "\n",
        "- Increase inference **speed up to 26x**\n",
        "\n",
        "- **Limit the memory** footprint on production up to **300x**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuxYCkCJuYD7"
      },
      "source": [
        "# Getting Started\n",
        "This section sets up the environment to get access to **HrFlow Profile API** and sets up a connection to HrFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyHzNdpwuYnz"
      },
      "source": [
        "# Machine Learning and Classification Libs\n",
        "!pip install --quiet tensorflow\n",
        "!pip install --quiet matplotlib\n",
        "!pip install --quiet pandas\n",
        "!pip install --quiet seaborn\n",
        "!pip install --quiet plotly\n",
        "!pip install --quiet tqdm\n",
        "\n",
        "# HrFlow Dependencies\n",
        "!pip install --quiet python-magic\n",
        "!pip install --quiet hrflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T8m_Vraucti"
      },
      "source": [
        "An **API Key** is required here. You can get your API Key at **https://```<your-sub domain/>```.hrflow.ai/settings/api/keys** or ask us for a **demo API Key**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZOVElmBudpi"
      },
      "source": [
        "import pprint\n",
        "from hrflow import Hrflow\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "# Credentials\n",
        "api_secret = getpass(prompt=\"Please Enter Your API Secret Key\")\n",
        "client = Hrflow(api_secret=api_secret)\n",
        "\n",
        "\n",
        "# Hrflow Synchronous Source\n",
        "source_key = getpass(prompt=\"Please Enter a Synchronous source_key\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMrGTO1pwvGN"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbHmEEbGukre"
      },
      "source": [
        "# 1. Building Dataset\n",
        "\n",
        "Dataset Folders Tree Structure:\n",
        "- webinar/dataset/\n",
        "    - resume/\n",
        "        - data_scientist/\n",
        "        - executive_manager/\n",
        "    - profile/\n",
        "        - data_scientist/\n",
        "        - executive_manager/\n",
        "    - embedding/\n",
        "        - data_scientist/\n",
        "        - executive_manager/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lE9oxNVuu6n"
      },
      "source": [
        "## 1.1. Setting Dataset Root"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fnx5BVP8rQ5"
      },
      "source": [
        "def build_path(path):\n",
        "  recursive_path = \"\"\n",
        "  for folder in path.split(\"/\"):\n",
        "    recursive_path = os.path.join(recursive_path, folder)\n",
        "    if not os.path.isdir(recursive_path):\n",
        "      os.mkdir(recursive_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCzltHHNumh5"
      },
      "source": [
        "import os\n",
        "\n",
        "# Dataset Root Folder\n",
        "DATASET_ROOT = \"drive/My Drive/webinar/dataset\"\n",
        "\n",
        "# Resume Folder\n",
        "data_scientist_resume_folder = os.path.join(DATASET_ROOT, \"resume\", \"data_scientist\")\n",
        "executive_manager_resume_folder = os.path.join(DATASET_ROOT, \"resume\", \"executive_manager\")\n",
        "\n",
        "# Parsing Folder\n",
        "data_scientist_parsing_folder = os.path.join(DATASET_ROOT, \"parsing\", \"data_scientist\")\n",
        "executive_manager_parsing_folder = os.path.join(DATASET_ROOT, \"parsing\", \"executive_manager\")\n",
        "build_path(data_scientist_parsing_folder)\n",
        "build_path(executive_manager_parsing_folder)\n",
        "\n",
        "# Profile Folder\n",
        "data_scientist_profile_folder = os.path.join(DATASET_ROOT, \"profile\", \"data_scientist\")\n",
        "executive_manager_profile_folder = os.path.join(DATASET_ROOT, \"profile\", \"executive_manager\")\n",
        "build_path(data_scientist_profile_folder)\n",
        "build_path(executive_manager_profile_folder)\n",
        "\n",
        "# Embedding Folder\n",
        "data_scientist_embedding_folder = os.path.join(DATASET_ROOT, \"embedding\", \"data_scientist\")\n",
        "executive_manager_embedding_folder = os.path.join(DATASET_ROOT, \"embedding\", \"executive_manager\")\n",
        "build_path(data_scientist_embedding_folder)\n",
        "build_path(executive_manager_embedding_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGM0JvnuxneB"
      },
      "source": [
        "print(os.listdir(data_scientist_resume_folder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5nKOIeBu22o"
      },
      "source": [
        "## 1.2. Parsing Resumes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLKLexusutvt"
      },
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "for folder, target_folder in [(data_scientist_resume_folder, data_scientist_parsing_folder), (executive_manager_resume_folder, executive_manager_parsing_folder)]:\n",
        "  file_names = os.listdir(folder)\n",
        "  for file_name in tqdm(file_names):\n",
        "      # Sending File for Parsing\n",
        "      file_path = os.path.join(folder, file_name)\n",
        "      with open(file_path, \"rb\") as file:\n",
        "          profile = file.read()\n",
        "          \n",
        "      response = client.profile.parsing.add_file(source_key=source_key, \n",
        "                                                 profile_file=profile,\n",
        "                                                 sync_parsing=1)\n",
        "      profile_parsing = response.get(\"data\").get(\"parsing\")\n",
        "      \n",
        "      # Saving Parsed Result\n",
        "      target_path = os.path.join(target_folder, file_name.split(\".\")[0])\n",
        "      with open(target_path,\"w\") as file:\n",
        "          json.dump(profile_parsing, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dP6unj4u5Sh"
      },
      "source": [
        "## 1.3. Downloading Profiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFKiftDVu8SZ"
      },
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "for folder, target_folder in [(data_scientist_parsing_folder, data_scientist_profile_folder), (executive_manager_parsing_folder, executive_manager_profile_folder)]:\n",
        "  file_names = os.listdir(folder)\n",
        "  for file_name in tqdm(file_names):\n",
        "      # Loading Parsing to get Profile Key\n",
        "      file_path = os.path.join(folder, file_name)\n",
        "      with open(file_path, \"r\") as file:\n",
        "          profile = json.load(file)\n",
        "\n",
        "      response = client.profile.indexing.get(source_key=source_key, \n",
        "                                             key=profile[\"key\"])\n",
        "      \n",
        "      profile = response.get(\"data\")\n",
        "      \n",
        "      # Saving Indexed Result\n",
        "      target_path = os.path.join(target_folder, file_name.split(\".\")[0])\n",
        "      with open(target_path,\"w\") as file:\n",
        "          json.dump(profile, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9McHfesIu948"
      },
      "source": [
        "## 1.4. Computing Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CoGYabIu_wZ"
      },
      "source": [
        "import base64\n",
        "import numpy as np\n",
        "\n",
        "def decode_embedding(base64_string):\n",
        "    output = base64.b64decode(base64_string)\n",
        "    output = np.frombuffer(output, dtype=np.dtype('>f4'))\n",
        "    output = np.reshape(output, (-1, 1024))\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fkzVghhvqQ1"
      },
      "source": [
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "folder = data_scientist_profile_folder\n",
        "target_folder = data_scientist_embedding_folder\n",
        "\n",
        "file_names = os.listdir(folder)\n",
        "\n",
        "\n",
        "for folder, target_folder in [(data_scientist_profile_folder, data_scientist_embedding_folder), (executive_manager_profile_folder, executive_manager_embedding_folder)]:\n",
        "  file_names = os.listdir(folder)\n",
        "  for file_name in tqdm(file_names):\n",
        "      # Loading Profile\n",
        "      file_path = os.path.join(folder, file_name)\n",
        "      with open(file_path, \"r\") as file:\n",
        "          profile = json.load(file)\n",
        "          \n",
        "      response = client.document.embedding.post(\"profile\", \n",
        "                                                profile, \n",
        "                                                return_sequences=True)\n",
        "      profile_embedding = decode_embedding(response.get(\"data\"))\n",
        "      \n",
        "      # Saving Embedded Result\n",
        "      target_path = os.path.join(target_folder, file_name.split(\".\")[0])\n",
        "      with open(target_path,\"wb\") as file:\n",
        "          pickle.dump(profile_embedding, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGT06v1LvBb0"
      },
      "source": [
        "## 1.5. Dataset Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brX1peuMwA9h"
      },
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Generator(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, file_paths, labels, batch_size=2):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.indices = np.arange(len(file_paths))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.file_paths) // self.batch_size\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = min(start + self.batch_size, len(self.file_paths))\n",
        "        batch_indices = self.indices[start:end]\n",
        "        batch_path = self.file_paths[batch_indices]\n",
        "        batch_labels = tf.constant(self.labels[batch_indices])\n",
        "        batch_profiles = []\n",
        "        for file_path in batch_path:\n",
        "            with open(file_path, \"rb\") as file:\n",
        "                profile = pickle.load(file)\n",
        "            batch_profiles.append(profile)\n",
        "        pad_length = max([element.shape[0] for element in batch_profiles])\n",
        "        batch_profiles = [tf.pad(element, [[0, pad_length-element.shape[0]], [0, 0]]) for element in batch_profiles]\n",
        "        batch_profiles = tf.stack(batch_profiles)\n",
        "        return batch_profiles, batch_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-CPtv6pwClg"
      },
      "source": [
        "data_scientist_paths = [os.path.join(data_scientist_embedding_folder, file) for file in os.listdir(data_scientist_embedding_folder)]\n",
        "executive_manager_paths = [os.path.join(executive_manager_embedding_folder, file) for file in os.listdir(executive_manager_embedding_folder)]\n",
        "\n",
        "file_paths = np.array(data_scientist_paths + executive_manager_paths)\n",
        "labels = np.array([0] * len(data_scientist_paths) + [1] * len(executive_manager_paths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maGFlSBYwDs8"
      },
      "source": [
        "generator = Generator(file_paths, labels)\n",
        "x, y = next(iter(generator))\n",
        "\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMX9bwWgwFRQ"
      },
      "source": [
        "# 2. Machine Learning With HrFlow.ai Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK03wDfAwJpN"
      },
      "source": [
        "## 2.1. Profile Classification and Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiH5YD8KwGsx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Masking, LSTM, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Profile Encoder Deduced From Classification Model Training\n",
        "model_input = Input(shape=(None, 1024), name=\"hrflow_embedding\")\n",
        "masking = Masking(name=\"masking\")(model_input)\n",
        "bi_lstm = Bidirectional(LSTM(8), name=\"bi_lstm\")(masking)\n",
        "dense = Dense(2, activation=\"tanh\", name=\"dense\")(bi_lstm)\n",
        "profile_encoder = Model(inputs=[model_input], outputs=[dense], name=\"profile_encoder\")\n",
        "\n",
        "# Scoring from Encoded Profile\n",
        "scoring_input = Input(shape=(2,))\n",
        "dropout = Dropout(0.2, name=\"dropout\")(scoring_input)\n",
        "softmax = Dense(2, activation='softmax', name=\"softmax\")(dropout) \n",
        "scoring = Model(inputs=[scoring_input], outputs=[softmax], name=\"profile_scoring\")\n",
        "\n",
        "\n",
        "# Classification Model\n",
        "profile_embedding = profile_encoder(model_input)\n",
        "profile_score = scoring(profile_embedding)\n",
        "model = Model(inputs=[model_input], outputs=[profile_score])\n",
        "model.compile(loss=SparseCategoricalCrossentropy(), \n",
        "              optimizer='nadam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih2qiDzNwMSZ"
      },
      "source": [
        "## 2.2. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw42Mj3TwN39"
      },
      "source": [
        "model.fit(generator, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL-VyCl1wQov"
      },
      "source": [
        "## 2.3. Embeddings and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pb6NEv0wZyL"
      },
      "source": [
        "def line_jump(text, every_char=50):\n",
        "    n_jumps = len(text) // every_char\n",
        "    output = text[:every_char]\n",
        "    for index in range(1, n_jumps):\n",
        "        output += '<br />' + text[every_char*index:every_char*(index+1)] \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atp5-4Y8wacS"
      },
      "source": [
        "import pickle\n",
        "import json\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "\n",
        "results = {\"text\": [], \"x\": [], \"y\": [], \"score\": [], \"label\": [], \"prediction\": []}\n",
        "\n",
        "for file_path, label in zip(file_paths, labels):\n",
        "    # Get Profile Label\n",
        "    results[\"label\"].append(label)\n",
        "    \n",
        "    # Get Profile Embedding\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        hrflow_embedding = pickle.load(file)\n",
        "    profile_embedding = profile_encoder.predict(np.expand_dims(hrflow_embedding, axis=0))[0]\n",
        "    x, y = profile_embedding\n",
        "    results[\"x\"].append(x)\n",
        "    results[\"y\"].append(y)\n",
        "    \n",
        "    # Get Profile Prediction\n",
        "    profile_score = model.predict(np.expand_dims(hrflow_embedding, axis=0))[0]\n",
        "    results[\"score\"].append(profile_score[1])\n",
        "    results[\"prediction\"].append(int(profile_score[1]>0.5))\n",
        "    \n",
        "    # Get Profile Summary\n",
        "    path = file_path.split(\"/\")\n",
        "    path[-3] = \"profile\"\n",
        "    with open(\"/\".join(path), \"r\") as file:\n",
        "        summary = json.load(file)[\"info\"][\"summary\"]\n",
        "    results[\"text\"].append(line_jump(summary))\n",
        "    \n",
        "df = DataFrame(results)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdNbalRMwfsg"
      },
      "source": [
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "# Compute Scores for Mesh Values\n",
        "xx = np.arange(-1, 1.1, 0.1)\n",
        "yy = np.arange(-1, 1.1, 0.1)\n",
        "mesh_values = np.array([scoring.predict(np.array([[x, y] for x in xx]))[:,1] for y in yy])\n",
        "\n",
        "# Contour/Boundary Plot\n",
        "data = go.Contour(x=xx, y=yy, z=mesh_values, \n",
        "                  colorscale=[[0.0, \"rgb(165,0,38)\"],\n",
        "                              [0.1111111111111111, \"rgb(215,48,39)\"],\n",
        "                              [0.2222222222222222, \"rgb(244,109,67)\"],\n",
        "                              [0.3333333333333333, \"rgb(253,174,97)\"],\n",
        "                              [0.4444444444444444, \"rgb(254,224,144)\"],\n",
        "                              [0.5555555555555556, \"rgb(224,243,248)\"],\n",
        "                              [0.6666666666666666, \"rgb(171,217,233)\"],\n",
        "                              [0.7777777777777778, \"rgb(116,173,209)\"],\n",
        "                              [0.8888888888888888, \"rgb(69,117,180)\"],\n",
        "                              [1.0, \"rgb(49,54,149)\"]])\n",
        "layout = {'width': 600, 'height': 600,\n",
        "          'xaxis_title': 'x', 'yaxis_title': 'y', \n",
        "          'xaxis': {'range': [-1, 1]}, 'yaxis': {'range': [-1, 1]},\n",
        "          'title': 'Decision Boundaries (Executive Managers in Yellow, Data Scientists in Blue)'}\n",
        "fig = go.Figure(data = data, layout=layout)\n",
        "\n",
        "# Profiles Embeddings\n",
        "scatter = px.scatter(df, x='x', y='y', \n",
        "                     hover_data=['summary', 'score', 'label', 'prediction'],\n",
        "                     color='prediction')\n",
        "fig.add_trace(scatter.data[0])\n",
        "\n",
        "# Show Graph\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}